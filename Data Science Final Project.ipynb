{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Disparities in State Voter Turnout: Culture or Policy?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Political scientists, for decades have often debated whether the low voter turnout in the USA is a question of cultural norms or voting policies. Many believe that even if we were to make voting in the United States substantially easier, we wouldn’t see large increases in turnout because the culture of voting doesn’t exist. What is often used is state by state data, where some political scientists will argue that because some states make it easier to vote, they have higher voter turnout rates (e.g. Minnesota), and the ones that don’t, see lower turnout rates (e.g. Georgia). Opponents of this theory will say that Minnesotans were always voting at a high level, and that culture of wanting to vote is what drove the policy changes, not the other way around. The way this has been traditionally studied is by grouping states into “cultural/geographic” segments, and then comparing turnout among them. \n",
    "\t\n",
    "Our project plan is to use data available from previous elections to test whether the differences among different states is cultural or policy oriented. We plan on doing this by constructing a data set that quantifies cultural things (i.e. demographics, geography, history of voter turnout, education rates, political participation in other forms), and using that to predict voter turnout rates. We’ll create a few training sets for regional groups, and then after training an algorithm on that, we’ll use it to compare different test sets to see if our predicted turnout rates differ from actual turnout rates. If the turnout rate of a state is predicted to be much higher than it is in reality, then one could argue that the cultural factors aren’t as important, and that there are policies in place that are preventing people from voting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we import the librarie we will be using throughout the course of the project:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will read in the 2009 and 2014 datasets, which will serve as the training dand testing data, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2009:\n",
      "   fips  statcode     areaname  relig09  civic09  bus09  pol09  prof09  \\\n",
      "0  1001         1  Autauga, AL     50.0      7.0    3.0    NaN     1.0   \n",
      "1  1003         1  Baldwin, AL    161.0     21.0    7.0    NaN     1.0   \n",
      "2  1005         1  Barbour, AL     17.0      1.0    1.0    NaN     NaN   \n",
      "3  1007         1     Bibb, AL     27.0      NaN    1.0    NaN     NaN   \n",
      "4  1009         1   Blount, AL     42.0      1.0    1.0    NaN     NaN   \n",
      "\n",
      "   labor09  bowl09  fitns09  golf09  sport09     pop09  respn10  nccs09  \\\n",
      "0      5.0     1.0      4.0     2.0      NaN   50756.0     0.78   182.0   \n",
      "1      2.0     2.0     18.0     8.0      NaN  179878.0     0.73   737.0   \n",
      "2      1.0     1.0      1.0     2.0      NaN   29737.0     0.63   107.0   \n",
      "3      NaN     NaN      1.0     1.0      NaN   21587.0     0.58    59.0   \n",
      "4      1.0     NaN      3.0     4.0      NaN   58345.0     0.80   121.0   \n",
      "\n",
      "     assn09   pvote08  \n",
      "0  1.438254  0.635648  \n",
      "1  1.223051  0.608996  \n",
      "2  0.807075  0.512425  \n",
      "3  1.389725  0.522517  \n",
      "4  0.891250  0.555640  \n",
      "2014:\n",
      "   FIPS  Religious2014  Civic2014  Business2014  Political2014  \\\n",
      "0  1001           53.0        7.0           3.0            NaN   \n",
      "1  1003          169.0       16.0           9.0            NaN   \n",
      "2  1005           19.0        1.0           1.0            NaN   \n",
      "3  1007           20.0        NaN           1.0            NaN   \n",
      "4  1009           39.0        NaN           1.0            NaN   \n",
      "\n",
      "   Professional2014  Labor2014  Bowling2014  Recreational2014  Golf2014  \\\n",
      "0               1.0        4.0          1.0               5.0       2.0   \n",
      "1               3.0        1.0          1.0              25.0       7.0   \n",
      "2               NaN        NaN          NaN               NaN       1.0   \n",
      "3               NaN        NaN          NaN               1.0       1.0   \n",
      "4               NaN        3.0          NaN               3.0       3.0   \n",
      "\n",
      "   Sports2014  pop2014  assn2014  respn2010  nccs2014  pvote2012  \n",
      "0         NaN    55290  1.374570       0.78     157.0   0.644956  \n",
      "1         NaN   199713  1.156660       0.73     718.0   0.674735  \n",
      "2         NaN    26815  0.820436       0.63      92.0   0.665031  \n",
      "3         NaN    22549  1.020001       0.58      54.0   0.656838  \n",
      "4         NaN    57658  0.849839       0.80     108.0   0.708668  \n"
     ]
    }
   ],
   "source": [
    "# Read in 2009 and 2014 datasets\n",
    "filename2009 = 'https://raw.githubusercontent.com/prathmj/SocialCapitalTurnoutStudy/master/Social%20Capital%202009%20with%20turnout.csv'\n",
    "filename2014 = 'https://raw.githubusercontent.com/prathmj/SocialCapitalTurnoutStudy/master/Social%20Capital%202014%20with%20turnout.csv'\n",
    "data2009 = pd.read_csv(filename2009)\n",
    "data2014 = pd.read_csv(filename2014)\n",
    "\n",
    "print(\"2009:\")\n",
    "print(data2009.head())\n",
    "print(\"2014:\")\n",
    "print(data2014.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we start to train any models, a bit of preprocessing is required, as performed below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2009:\n",
      "   fips  statcode     areaname  relig09  civic09  bus09  pol09  prof09  \\\n",
      "0  1001         1  Autauga, AL     50.0      7.0    3.0    0.0     1.0   \n",
      "1  1003         1  Baldwin, AL    161.0     21.0    7.0    0.0     1.0   \n",
      "2  1005         1  Barbour, AL     17.0      1.0    1.0    0.0     0.0   \n",
      "3  1007         1     Bibb, AL     27.0      0.0    1.0    0.0     0.0   \n",
      "4  1009         1   Blount, AL     42.0      1.0    1.0    0.0     0.0   \n",
      "\n",
      "   labor09  bowl09  fitns09  golf09  sport09     pop09  respn10  nccs09  \\\n",
      "0      5.0     1.0      4.0     2.0      0.0   50756.0     0.78   182.0   \n",
      "1      2.0     2.0     18.0     8.0      0.0  179878.0     0.73   737.0   \n",
      "2      1.0     1.0      1.0     2.0      0.0   29737.0     0.63   107.0   \n",
      "3      0.0     0.0      1.0     1.0      0.0   21587.0     0.58    59.0   \n",
      "4      1.0     0.0      3.0     4.0      0.0   58345.0     0.80   121.0   \n",
      "\n",
      "     assn09   pvote08  \n",
      "0  1.438254  0.635648  \n",
      "1  1.223051  0.608996  \n",
      "2  0.807075  0.512425  \n",
      "3  1.389725  0.522517  \n",
      "4  0.891250  0.555640  \n",
      "2014:\n",
      "   FIPS  Religious2014  Civic2014  Business2014  Political2014  \\\n",
      "0  1001           53.0        7.0           3.0            0.0   \n",
      "1  1003          169.0       16.0           9.0            0.0   \n",
      "2  1005           19.0        1.0           1.0            0.0   \n",
      "3  1007           20.0        0.0           1.0            0.0   \n",
      "4  1009           39.0        0.0           1.0            0.0   \n",
      "\n",
      "   Professional2014  Labor2014  Bowling2014  Recreational2014  Golf2014  \\\n",
      "0               1.0        4.0          1.0               5.0       2.0   \n",
      "1               3.0        1.0          1.0              25.0       7.0   \n",
      "2               0.0        0.0          0.0               0.0       1.0   \n",
      "3               0.0        0.0          0.0               1.0       1.0   \n",
      "4               0.0        3.0          0.0               3.0       3.0   \n",
      "\n",
      "   Sports2014  pop2014  assn2014  respn2010  nccs2014  pvote2012  \n",
      "0         0.0    55290  1.374570       0.78     157.0   0.644956  \n",
      "1         0.0   199713  1.156660       0.73     718.0   0.674735  \n",
      "2         0.0    26815  0.820436       0.63      92.0   0.665031  \n",
      "3         0.0    22549  1.020001       0.58      54.0   0.656838  \n",
      "4         0.0    57658  0.849839       0.80     108.0   0.708668  \n"
     ]
    }
   ],
   "source": [
    "# Impute missing values with 0\n",
    "data2009 = data2009.fillna(value=0)\n",
    "data2014 = data2014.fillna(value=0)\n",
    "\n",
    "# Separate into x and y\n",
    "X2009 = data2009.iloc[:, :-1]  # features\n",
    "y2009 = data2009.iloc[:, -1]  # class (turnout)\n",
    "\n",
    "X2014 = data2014.iloc[:, :-1]  # features\n",
    "y2014 = data2014.iloc[:, -1]  # class (turnout)\n",
    "\n",
    "# Encode\n",
    "le = LabelEncoder()\n",
    "le.fit(y2009)\n",
    "y2009 = le.transform(y2009)\n",
    "le.fit(y2014)\n",
    "y2014 = le.transform(y2014)\n",
    "\n",
    "print(\"2009:\")\n",
    "print(data2009.head())\n",
    "print(\"2014:\")\n",
    "print(data2014.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will visualize the data using various graphs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
